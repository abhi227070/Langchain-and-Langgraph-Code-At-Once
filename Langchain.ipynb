{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72280e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Output: The capital of France is **Paris**.\n",
      "NVIDIA Output: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Langchain models with appropriate parameters\n",
    "gemini_model = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0.2)\n",
    "nvidia_model = ChatNVIDIA(model=\"meta/llama-3.2-3b-instruct\", temperature=0.1)\n",
    "\n",
    "# Example usage of the models\n",
    "gemini_response = gemini_model.invoke(\"What is the capital of France?\")\n",
    "print(f\"Gemini Output: {gemini_response.content}\")\n",
    "\n",
    "nvidia_response = nvidia_model.invoke(\"What is the capital of France?\")\n",
    "print(f\"NVIDIA Output: {nvidia_response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0dfb88cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Template: What is the capital of France?\n",
      "Chat Prompt Template: messages=[SystemMessage(content='You are a helpful assistant for python coding.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={})]\n",
      "Few Shot Prompt Template: Translate the following phrases:\n",
      "\n",
      "\n",
      "Input: Translate 'hello' to Spanish.\n",
      "Output: Hola.\n",
      "\n",
      "Input: Translate 'thank you' to French.\n",
      "Output: Merci.\n",
      "\n",
      "Input: Translate Hello world into Hindi\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Trying different prompt templates in langchain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# Prompt Templates\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "# Chat Prompt Template\n",
    "chat_prompt_template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"You are a helpful assistant for python coding.\"),\n",
    "        (\"user\", \"{question}\")\n",
    "    ],\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "# Few Shot Prompt Template\n",
    "examples = [\n",
    "    {\"input\": \"Translate 'hello' to Spanish.\", \"output\": \"Hola.\"},\n",
    "    {\"input\": \"Translate 'thank you' to French.\", \"output\": \"Merci.\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\"\n",
    ")\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Translate the following phrases:\\n\",\n",
    "    suffix=\"Input: {query}\\nOutput:\",\n",
    "    input_variables=[\"query\"]\n",
    ")\n",
    "\n",
    "# Example usage of the prompt templates\n",
    "print(f\"Prompt Template: {prompt_template.invoke({'country': 'France'}).text}\")\n",
    "print(f\"Chat Prompt Template: {chat_prompt_template.invoke({'question': 'What is the capital of France?'})}\")\n",
    "print(f\"Few Shot Prompt Template: {few_shot_prompt_template.invoke({'query': 'Translate Hello world into Hindi'}).text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bec16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Combined Output: The capital of India is **New Delhi**.\n",
      "NVIDIA Combined Output: The capital of India is New Delhi.\n",
      "Gemini Chat Output: Of course! Here are several ways to reverse a string in Python, from the most common and \"Pythonic\" to more fundamental approaches.\n",
      "\n",
      "### 1. The Best and Most Pythonic Way: Slicing\n",
      "\n",
      "This is the most concise and widely used method in Python. It uses extended slice syntax.\n",
      "\n",
      "**Code:**\n",
      "```python\n",
      "original_string = \"hello world\"\n",
      "\n",
      "# The magic happens here: [::-1]\n",
      "reversed_string = original_string[::-1]\n",
      "\n",
      "print(f\"Original: {original_string}\")\n",
      "print(f\"Reversed: {reversed_string}\")\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "```\n",
      "Original: hello world\n",
      "Reversed: dlrow olleh\n",
      "```\n",
      "\n",
      "**How it works:**\n",
      "The slice syntax is `[start:stop:step]`.\n",
      "*   By leaving `start` and `stop` blank (`:`), we specify the entire string.\n",
      "*   By setting `step` to `-1`, we tell Python to go backward one character at a time.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Using the `reversed()` Function and `join()`\n",
      "\n",
      "This method is also very Pythonic and can be more readable for people unfamiliar with the slice trick.\n",
      "\n",
      "**Code:**\n",
      "```python\n",
      "original_string = \"Python is fun\"\n",
      "\n",
      "# reversed() returns an iterator that yields characters in reverse order\n",
      "# \"\".join() concatenates them back into a string\n",
      "reversed_string = \"\".join(reversed(original_string))\n",
      "\n",
      "print(f\"Original: {original_string}\")\n",
      "print(f\"Reversed: {reversed_string}\")\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "```\n",
      "Original: Python is fun\n",
      "Reversed: nuf si nohtyP\n",
      "```\n",
      "\n",
      "**How it works:**\n",
      "1.  `reversed(original_string)` creates an *iterator* that goes through the string from end to start.\n",
      "2.  `\"\".join(...)` takes all the items from the iterator and joins them together into a new string. The `\"\"` at the beginning means there is no separator between the characters.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Using a `for` Loop (The Manual Way)\n",
      "\n",
      "This approach builds the reversed string character by character. It's a great way to understand the underlying logic and is common in other programming languages.\n",
      "\n",
      "**Code:**\n",
      "```python\n",
      "original_string = \"programming\"\n",
      "reversed_string = \"\"\n",
      "\n",
      "# Iterate through each character in the original string\n",
      "for char in original_string:\n",
      "  # Prepend the character to the new string\n",
      "  reversed_string = char + reversed_string\n",
      "\n",
      "print(f\"Original: {original_string}\")\n",
      "print(f\"Reversed: {reversed_string}\")\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "```\n",
      "Original: programming\n",
      "Reversed: gnimmargorp\n",
      "```\n",
      "**How it works:**\n",
      "The loop reads the `original_string` from left to right (`p`, then `r`, then `o`...). In each step, it takes the current character (`char`) and places it at the *beginning* of the `reversed_string`.\n",
      "\n",
      "- **Iteration 1:** `char` is 'p'. `reversed_string` becomes 'p' + \"\" -> \"p\"\n",
      "- **Iteration 2:** `char` is 'r'. `reversed_string` becomes 'r' + \"p\" -> \"rp\"\n",
      "- **Iteration 3:** `char` is 'o'. `reversed_string` becomes 'o' + \"rp\" -> \"orp\"\n",
      "- ...and so on.\n",
      "\n",
      "---\n",
      "\n",
      "### Putting it into a Reusable Function\n",
      "\n",
      "It's good practice to wrap this logic in a function. Here's how you would do it using the recommended slicing method.\n",
      "\n",
      "```python\n",
      "def reverse_string(s):\n",
      "  \"\"\"\n",
      "  Reverses a given string using slicing.\n",
      "\n",
      "  Args:\n",
      "    s: The string to be reversed.\n",
      "\n",
      "  Returns:\n",
      "    The reversed string.\n",
      "  \"\"\"\n",
      "  return s[::-1]\n",
      "\n",
      "# --- Example Usage ---\n",
      "my_name = \"Alice\"\n",
      "reversed_name = reverse_string(my_name)\n",
      "print(f\"{my_name} reversed is {reversed_name}\") # Output: Alice reversed is ecilA\n",
      "\n",
      "another_string = \"racecar\"\n",
      "print(f\"{another_string} reversed is {reverse_string(another_string)}\") # Output: racecar reversed is racecar\n",
      "```\n",
      "\n",
      "### Summary: Which Method Should You Use?\n",
      "\n",
      "| Method | Readability | Performance | \"Pythonic\" | When to Use |\n",
      "| :--- | :--- | :--- | :--- | :--- |\n",
      "| **Slicing `[::-1]`** | Good, once you know the trick | **Excellent** | **Most Pythonic** | **Your default choice.** It's fast, concise, and idiomatic. |\n",
      "| **`\"\".join(reversed())`** | **Excellent** | Excellent | Very Pythonic | When you want maximum clarity. It explicitly says \"reversed\" and \"join\". |\n",
      "| **`for` Loop** | Good | Good (but slower for very long strings) | Less Pythonic | When you're learning, or in a coding interview to demonstrate you understand the fundamentals without relying on built-in tricks. |\n",
      "NVIDIA Chat Output: **Reversing a String in Python**\n",
      "================================\n",
      "\n",
      "You can reverse a string in Python using slicing or the built-in `reversed` function. Here are examples of both methods:\n",
      "\n",
      "### Method 1: Using Slicing\n",
      "\n",
      "```python\n",
      "def reverse_string_slicing(input_str):\n",
      "    \"\"\"\n",
      "    Reverses a string using slicing.\n",
      "\n",
      "    Args:\n",
      "        input_str (str): The input string to be reversed.\n",
      "\n",
      "    Returns:\n",
      "        str: The reversed string.\n",
      "    \"\"\"\n",
      "    return input_str[::-1]\n",
      "\n",
      "# Example usage:\n",
      "input_str = \"Hello, World!\"\n",
      "reversed_str = reverse_string_slicing(input_str)\n",
      "print(reversed_str)  # Output: \"!dlroW ,olleH\"\n",
      "```\n",
      "\n",
      "### Method 2: Using the `reversed` Function\n",
      "\n",
      "```python\n",
      "def reverse_string_reversed(input_str):\n",
      "    \"\"\"\n",
      "    Reverses a string using the reversed function.\n",
      "\n",
      "    Args:\n",
      "        input_str (str): The input string to be reversed.\n",
      "\n",
      "    Returns:\n",
      "        str: The reversed string.\n",
      "    \"\"\"\n",
      "    return \"\".join(reversed(input_str))\n",
      "\n",
      "# Example usage:\n",
      "input_str = \"Hello, World!\"\n",
      "reversed_str = reverse_string_reversed(input_str)\n",
      "print(reversed_str)  # Output: \"!dlroW ,olleH\"\n",
      "```\n",
      "\n",
      "### Method 3: Using a Loop\n",
      "\n",
      "```python\n",
      "def reverse_string_loop(input_str):\n",
      "    \"\"\"\n",
      "    Reverses a string using a loop.\n",
      "\n",
      "    Args:\n",
      "        input_str (str): The input string to be reversed.\n",
      "\n",
      "    Returns:\n",
      "        str: The reversed string.\n",
      "    \"\"\"\n",
      "    reversed_str = \"\"\n",
      "    for char in input_str:\n",
      "        reversed_str = char + reversed_str\n",
      "    return reversed_str\n",
      "\n",
      "# Example usage:\n",
      "input_str = \"Hello, World!\"\n",
      "reversed_str = reverse_string_loop(input_str)\n",
      "print(reversed_str)  # Output: \"!dlroW ,olleH\"\n",
      "```\n",
      "\n",
      "Choose the method that best suits your needs. The slicing method is generally the most efficient and Pythonic way to reverse a string.\n",
      "Gemini Few Shot Output: नमस्ते दुनिया (Namaste Duniya)\n",
      "NVIDIA Few Shot Output: Input: Translate 'Hello world' to Hindi.\n",
      "Output: नमस्ते दुनिया (Namaste Duniya)\n"
     ]
    }
   ],
   "source": [
    "# Prompt Templates + Models\n",
    "gemini_prompt_template = prompt_template | gemini_model\n",
    "nvidia_prompt_template = prompt_template | nvidia_model\n",
    "\n",
    "# Chat Prompt Templates + Models\n",
    "gemini_chat_prompt_template = chat_prompt_template | gemini_model\n",
    "nvidia_chat_prompt_template = chat_prompt_template | nvidia_model\n",
    "\n",
    "# Few Shot Prompt Templates + Models\n",
    "gemini_few_shot_prompt_template = few_shot_prompt_template | gemini_model\n",
    "nvidia_few_shot_prompt_template = few_shot_prompt_template | nvidia_model\n",
    "\n",
    "# Example usage of the combined prompt templates and models\n",
    "gemini_combined_response = gemini_prompt_template.invoke({\"country\": \"India\"})\n",
    "nvidia_combined_response = nvidia_prompt_template.invoke({\"country\": \"India\"})\n",
    "print(f\"Gemini Combined Output: {gemini_combined_response.content}\")\n",
    "print(f\"NVIDIA Combined Output: {nvidia_combined_response.content}\")\n",
    "\n",
    "# Example usage of the chat prompt templates with models\n",
    "gemini_chat_response = gemini_chat_prompt_template.invoke({\"question\": \"Write python code to reverse a string.\"})\n",
    "nvidia_chat_response = nvidia_chat_prompt_template.invoke({\"question\": \"Write python code to reverse a string?\"})\n",
    "print(f\"Gemini Chat Output: {gemini_chat_response.content}\")\n",
    "print(f\"NVIDIA Chat Output: {nvidia_chat_response.content}\")\n",
    "\n",
    "# Example usage of the few shot prompt templates with models\n",
    "gemini_few_shot_response = gemini_few_shot_prompt_template.invoke({\"query\": \"Translate Hello world into Hindi\"})\n",
    "nvidia_few_shot_response = nvidia_few_shot_prompt_template.invoke({\"query\": \"Translate Hello world into Hindi\"})\n",
    "print(f\"Gemini Few Shot Output: {gemini_few_shot_response.content}\")\n",
    "print(f\"NVIDIA Few Shot Output: {nvidia_few_shot_response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5c53899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a friendly Chatbot.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hii My name is Abhijit.', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello there. Nice to meet you, Abhijit!', additional_kwargs={}, response_metadata={}), HumanMessage(content='I am from India and I am learning about Langchain.', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Ohh that's great. Langhain is a powerful framework for building applications with language models. What would you like to know about it?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Message PlaceHolders\n",
    "# Define a chat prompt template with messages\n",
    "message_placeholder_prompt = ChatPromptTemplate(\n",
    "    messages= [\n",
    "        (\"system\", \"You are a friendly Chatbot.\"),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{user_query}\"),  \n",
    "    ],\n",
    "    input_variables=[\"country\", \"chat_history\"]\n",
    ")\n",
    "\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Hii My name is Abhijit.\"),\n",
    "    AIMessage(content=\"Hello there. Nice to meet you, Abhijit!\"),\n",
    "    HumanMessage(content=\"I am from India and I am learning about Langchain.\"),\n",
    "    AIMessage(content=\"Ohh that's great. Langhain is a powerful framework for building applications with language models. What would you like to know about it?\"),\n",
    "]\n",
    "\n",
    "final_response = message_placeholder_prompt.invoke({\n",
    "    \"user_query\": \"What is my name?\",\n",
    "    \"chat_history\": chat_history\n",
    "})\n",
    "\n",
    "final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12df6bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini with Placeholder Memory Output: Your name is Abhijit! You told me when we first started chatting. 😊\n",
      "NVIDIA with Placeholder Memory Output: Your name is Abhijit.\n"
     ]
    }
   ],
   "source": [
    "gemini_with_placeholder_memory = message_placeholder_prompt | gemini_model\n",
    "nvidia_with_placeholder_memory = message_placeholder_prompt | nvidia_model\n",
    "\n",
    "# Example usage of the models with message placeholders\n",
    "print(f\"Gemini with Placeholder Memory Output: {gemini_with_placeholder_memory.invoke({'chat_history': chat_history, 'user_query': 'What is my name?'}).content}\")\n",
    "print(f\"NVIDIA with Placeholder Memory Output: {nvidia_with_placeholder_memory.invoke({'chat_history': chat_history, 'user_query': 'What is my name?'}).content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7754c5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured Response: {'name': 'Devika', 'age': 25, 'email': None, 'gender': 'Female'}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# With Structured Output\n",
    "# Define a structured output model using Pydantic\n",
    "class UserProfile(BaseModel):\n",
    "    name: Annotated[str, Field(description=\"The user's name\")]\n",
    "    age: Optional[Annotated[int, Field(description=\"The user's age, if provided\", ge=0, le=120)]] = None\n",
    "    email: Optional[Annotated[str, Field(description=\"The user's email address\")]] = None\n",
    "    gender: Annotated[Literal[\"Male\", \"Female\"], Field(description=\"The user's gender. If not provided then use your best guess\")]\n",
    "\n",
    "# Create a prompt template for structured output  \n",
    "gemini_structured = gemini_model.with_structured_output(UserProfile)\n",
    "prompt_template_structured = PromptTemplate(\n",
    "    template=\"fetch the user details like name, age and email from the user query: {query}\",\n",
    "    input_variables=[\"query\"]\n",
    ")\n",
    "\n",
    "# Combine the prompt template with the model for structured output\n",
    "structured_chain = prompt_template_structured | gemini_structured\n",
    "structured_response = structured_chain.invoke({\"query\": \"My name is Devika, I am 25 years old.\"})\n",
    "structured_response = structured_response.model_dump()  # Convert to dictionary for easier access\n",
    "\n",
    "# Print the structured response\n",
    "print(f\"Structured Response: {structured_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3a9db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Details: {'name': 'Galaxy S21', 'price': 799.99, 'in_stock': False}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser, JsonOutputParser\n",
    "\n",
    "# Define a Pydantic model for product details\n",
    "class Product(BaseModel):\n",
    "    name: Annotated[str, Field(description=\"The name of the product\")]\n",
    "    price: Annotated[float, Field(description=\"The price of the product in USD\")]\n",
    "    in_stock: Annotated[bool, Field(description=\"Whether the product is in stock\")]\n",
    "    \n",
    "# Define output parsers\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=Product)\n",
    "\n",
    "# Define a prompt template for extracting product details\n",
    "prompt_template_product = PromptTemplate(\n",
    "    template=\"\"\"Extract product details from the following text: \n",
    "    {text}\n",
    "    format instructions: {format_instructions}\"\"\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Create a chain that combines the prompt template and the model with the Pydantic parser\n",
    "product_chain = prompt_template_product | gemini_model | pydantic_parser\n",
    "product_response = product_chain.invoke({\n",
    "    \"text\": \"The product is a smartphone named 'Galaxy S21', priced at 799.99 USD, and it is currently out of stock.\"\n",
    "})\n",
    "\n",
    "print(f\"Product Details: {product_response.model_dump()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71d409c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple String Output: The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "# Simple String Output Parser\n",
    "simple_string_parser = StrOutputParser()\n",
    "simple_string_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "# Combine the simple string template with the model\n",
    "simple_string_chain = simple_string_template | gemini_model | simple_string_parser\n",
    "simple_string_response = simple_string_chain.invoke({\"country\": \"France\"})\n",
    "\n",
    "print(f\"Simple String Output: {simple_string_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076fbfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
